<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>What I talk about when I don&#39;t talk about me</title>
    <link>/</link>
    <description>Recent content on What I talk about when I don&#39;t talk about me</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 26 Nov 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
<<<<<<< HEAD
      <title>Second Language Acquisition Modeling using Duolingo&#39;s Data</title>
      <link>/2018/11/26/second-language-acquisition-modeling/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/26/second-language-acquisition-modeling/</guid>
      <description>Background Recently, I have discovered the Second Language Acquisition Modeling (SLAM) challenge hosted by Duolingo earlier this year, where they had asked the participants to predict the per-token error rate for a given language learner based on his/her past learning history. To conclude the competition, the team has also written a paper to summarize the results and the approaches that were taken by the various participants and their respective effectiveness.</description>
    </item>
    
    <item>
      <title>Les lobbys aux Etats-Unis</title>
      <link>/2018/10/03/les-lobbys-aux-etats-unis/</link>
      <pubDate>Wed, 03 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/03/les-lobbys-aux-etats-unis/</guid>
      <description>En thÃ©orie (du moins dâ€™aprÃ¨s les lobbys eux-mÃªmes), le gouvernement a besoin des lobbys parce quâ€™il faut avoir toutes les informations et toutes les opinions avant de prendre une dÃ©cision. Donc, avoir des lobbys indÃ©pendants qui reprÃ©sentent les intÃ©rÃªts de nombreuses parties est une condition fondamentale pour la dÃ©mocratie. Le problÃ¨me, pourtant, câ€™est en rÃ©alitÃ© les lobbys ne sont ni indÃ©pendants ni reprÃ©sentatifs des citoyens.
La National Rifle Association (NRA), lâ€™un des plus grands et plus puissants lobbys aux Etats-Unis, illustre clairement comment ce systÃ¨me fonctionne en rÃ©alitÃ©.</description>
    </item>
    
    <item>
      <title>Le projet de crÃ©dit social en Chine</title>
      <link>/2018/09/21/le-projet-de-cr%C3%A9dit-social-en-chine/</link>
      <pubDate>Fri, 21 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/21/le-projet-de-cr%C3%A9dit-social-en-chine/</guid>
      <description>Quand jâ€™ai entendu que le gouvernement chinois avait annoncÃ© un systÃ¨me de crÃ©dit social, jâ€™ai eu une impression de dÃ©jÃ -vu. Enfin, ce ne sera ni la premiÃ¨re ni la derniÃ¨re fois que notre gouvernement essaie de rÃ©guler la sociÃ©tÃ© par le biais dâ€™une surveillance centrale et mutuelle. Maintenant, le gouvernement a Ã©normÃ©ment dâ€™expÃ©rience quand il sâ€™agit dâ€™unir les citoyens et de les convaincre de travailler pour nâ€™importe quel objectif central mÃªme si Ã§a leur demande de se tourner le dos.</description>
    </item>
    
    <item>
      <title>Lâ€™assimilation vs. le multiculturalisme</title>
      <link>/2018/09/09/l-assimilation-vs-le-multiculturalisme/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/09/l-assimilation-vs-le-multiculturalisme/</guid>
      <description>RÃ©cemment, inspirÃ© par lâ€™actualitÃ©, jâ€™ai beaucoup rÃ©flÃ©chi sur le sujet de lâ€™immigration, en particulier, sur les diffÃ©rences entre le modÃ¨le de lâ€™assimilation, comme celui adoptÃ© par France, et le modÃ¨le de multiculturalisme, comme celui adoptÃ© par les Etats-Unis. En gros, lâ€™assimilation demande que les immigrÃ©s sâ€™intÃ¨grent Ã  la sociÃ©tÃ© du pays dâ€™accueil rapidement et discrÃ¨tement alors que le multiculturalisme demande que les autochtones tolÃ¨rent les diffÃ©rentes cultures et accueillent les changements.</description>
    </item>
    
    <item>
      <title>La joie dâ€™Ãªtre Ã©tranger</title>
      <link>/2018/05/06/la-joie-d-%C3%AAtre-%C3%A9tranger/</link>
      <pubDate>Sun, 06 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/06/la-joie-d-%C3%AAtre-%C3%A9tranger/</guid>
      <description>DÃ¨s que jâ€™Ã©tait petit, je rÃªvais de voyager Ã  lâ€™Ã©tranger. En fait, quand jâ€™avais cinq ou six ans, mes parents mâ€™ont enregistrÃ© en parlant de ce que je voudrais faire quand je sera grand et jâ€™ai dit avec confiance que jâ€™aimerais voir et vivre dans les pays diffÃ©rents, ce que je nâ€™ai jamais oubliÃ©.
Câ€™est pour Ã§a que jâ€™aime toujours apprendre les langues Ã©trangÃ¨res. A lâ€™Ã©cole, mon cours prÃ©fÃ©rÃ© Ã©tait lâ€™anglais et jâ€™ai lu beaucoup de littÃ©rature Ã©trangÃ¨re et vu beaucoup de films.</description>
    </item>
    
    <item>
      <title>Syndrome de lâ€™imposteur</title>
      <link>/2018/04/08/syndrome-de-l-imposteur/</link>
      <pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/08/syndrome-de-l-imposteur/</guid>
      <description>Ã‡a fait longtemps que jâ€™ai voulu Ã©crire quelque chose sur le syndrome de lâ€™imposteur. Enfin câ€™est un sujet trÃ¨s personnel pour moi. Oui, je me sens comme un imposteur pendant toute ma carriÃ¨re en tant que data scientist. Donc, je crois que jâ€™ai beaucoup dâ€™expÃ©rience Ã  partager.
Au dÃ©but, câ€™Ã©tait que jâ€™avais peur de ne pas avoir Ã©tudiÃ© assez de statistiques Ã  lâ€™universitÃ©, ce qui fait quâ€™il fallait que jâ€™en apprenne beaucoup sur travail.</description>
    </item>
    
    <item>
||||||| merged common ancestors
=======
      <title>Second Language Acquisition Modeling using Duolingo&#39;s Data</title>
      <link>/2018/11/26/second-language-acquisition-modeling/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/26/second-language-acquisition-modeling/</guid>
      <description>Background Recently, I have discovered the Second Language Acquisition Modeling (SLAM) challenge hosted by Duolingo earlier this year, where they had asked the participants to predict the per-token error rate for a given language learner based on his/her past learning history. To conclude the competition, the team has also written a paper to summarize the results and the approaches that were taken by the various participants and their respective effectiveness.</description>
    </item>
    
    <item>
>>>>>>> d87c22a6902abb3cfceca419cbebab6553de94fe
      <title>Second attempt at building a language translator</title>
      <link>/2017/09/07/second-attempt-at-building-a-language-translator/</link>
      <pubDate>Thu, 07 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/07/second-attempt-at-building-a-language-translator/</guid>
      <description>Update Recently, upon various trials and errors, I have finally implemented the same model in Keras (GitHub), largely thanks to the deep learning course offered by Andrew Ng on Coursera (especially the one on sequence models) and, obviously, Stack Overflow. ğŸ™
Below are the original post:
 â€”â€”â€”â€” Background A few weeks ago, I experimented with building a language translator using a simple sequence-to-sequence model. Since then, I had been itchy to add an extra attention layer to it that I had been reading so much about.</description>
    </item>
    
    <item>
      <title>First attempt at building a language translator</title>
      <link>/2017/08/14/first-attempt-at-building-a-language-translator/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/14/first-attempt-at-building-a-language-translator/</guid>
      <description>Background After having tried my hands on LSTM and built a text generater, I became interested in the sequence-to-sequence models, particularly their applications in language translations. It all started with this TensorFlow tutorial where the authors demonstrated how they built an English-to-French translator using such a model and successfully translated &amp;ldquo;Who is the president of the United States?&amp;rdquo; into French with the correct grammar (&amp;ldquo;Qui est le prÃ©sident des Ã‰tats-Unis?</description>
    </item>
    
    <item>
      <title>When Jane Austen, Oscar Wilde, and F. Scott Fitzgerald walk into a bar</title>
      <link>/2017/07/27/when-jane-austen-oscar-wilde-and-f-scott-fitzgerald-walk-into-a-bar/</link>
      <pubDate>Thu, 27 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/07/27/when-jane-austen-oscar-wilde-and-f-scott-fitzgerald-walk-into-a-bar/</guid>
      <description>Background Lately I&amp;rsquo;ve been spending a lot of time learning about deep learning, particularly its applications in natural language processing, a field I have been immensely interested in. Before deep learning, my foray into NLP has been mainly about sentiment analysis1 and topic modeling.2 These projects are fun but they are all limited in analyzing an existing corpus of text whereas I&amp;rsquo;m also interested in applications that generate texts themselves.</description>
    </item>
    
    <item>
      <title>An analysis of foreign language learning using Duolingo&#39;s data</title>
      <link>/2017/07/02/an-analysis-of-foreign-language-learning-using-duolingo-data/</link>
      <pubDate>Sun, 02 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/07/02/an-analysis-of-foreign-language-learning-using-duolingo-data/</guid>
      <description>Background Earlier this year, I decided to learn French, something I&amp;rsquo;ve been thinking about for a long time. Foreign language learning has always been something magical to me: I had a great time learning English when I was at school (my mother tongue is Mandarin Chinese), so much that I would devote all my time to it and ignore my other subjects (not recommended). Hence, when I signed up for a beginner&amp;rsquo;s class in my local Alliance FranÃ§aise and started taking classes regularly, it felt homecoming to me.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Thu, 05 May 2016 21:48:51 -0700</pubDate>
      
      <guid>/about/</guid>
      <description>Hi,
This is my dog and, if you look carefully, that is me behind:
I&amp;rsquo;m a data scientist by day and a language learner by night. In this blog, I write about my data science side projects 90% of the time and opine about society, culture, and globalization in broken French in the remaining 10%. I should&amp;rsquo;ve probably kept them separate but neither alone would have represented me well.</description>
    </item>
    
    <item>
      <title>Predicting Yelp ratings using textual reviews</title>
      <link>/2014/12/30/predicting-yelp-ratings-using-textual-reviews/</link>
      <pubDate>Tue, 30 Dec 2014 02:04:42 +0000</pubDate>
      
      <guid>/2014/12/30/predicting-yelp-ratings-using-textual-reviews/</guid>
      <description>Internet is truly full of free and fascinating datasets! I found this Yelp Dataset Challenge the other day that includes, among others, over 1 million reviews (most of which are recent) along with their respective 5-star ratings - excellent text mining material! Although to enter the competition (which ends on 12/31/14), you have to be a current student (which I&amp;rsquo;m not), but everyone is welcome to play around with the data.</description>
    </item>
    
    <item>
      <title>Notes to machine learning</title>
      <link>/2014/11/15/notes-to-machine-learning/</link>
      <pubDate>Sat, 15 Nov 2014 22:21:43 +0000</pubDate>
      
      <guid>/2014/11/15/notes-to-machine-learning/</guid>
      <description>Data transformation Resampling techniques Regression models Smoothing Neural networks Support vector machines K-nearest neighbors Trees Random forests Gradient boosting trees Cubist Measuring performace in classification models Linear classificatoin models Latent Dirichlet allocation   These are the notes I took while reading An Introduction to Statistical Learning and Applied Predictive Modeling. Some of the notes also came from other sources, but the majority of them are from these two books.</description>
    </item>
    
    <item>
      <title>Quora challenge - answer classification</title>
      <link>/2014/11/15/answer_classification/</link>
      <pubDate>Sat, 15 Nov 2014 22:15:22 +0000</pubDate>
      
      <guid>/2014/11/15/answer_classification/</guid>
      <description>Last night I tried my hands on a Quora challengeÂ that classifies user-submitted answers into &amp;lsquo;good&amp;rsquo; and &amp;lsquo;bad.&amp;rsquo; All the information is anonymized, including the variable names, but you can tell by looking at their values what some of them may represent. For example, some appear to be count data or some summary statistics based on them, and, given that many of the values are 0 and heavily right-skewed, they seem to be some measure of the writers&amp;rsquo; reputations,Â the number of upvotes an answerÂ received, or the follow-up comments.</description>
    </item>
    
    <item>
      <title>Building a book recommender</title>
      <link>/2014/10/04/building-a-book-recommender/</link>
      <pubDate>Sat, 04 Oct 2014 20:53:36 +0000</pubDate>
      
      <guid>/2014/10/04/building-a-book-recommender/</guid>
      <description>Lately, I&amp;rsquo;ve become very interested in text mining and topic modeling, and have played around withÂ some popular algorithms like LDA. However, so far my projects have all been centered around what I can learn from a giant chunk of texts and usually stopped afterÂ I extracted some revealing and, if I&amp;rsquo;m lucky, thought-provoking topicsÂ fromÂ them. In other words, what I&amp;rsquo;ve been doing so far is all inference butÂ no predictions.</description>
    </item>
    
    <item>
      <title>Analyzing å…«é›¶å (China&#39;s post-80s )</title>
      <link>/2014/09/26/analyzing-chinas-post-80s/</link>
      <pubDate>Fri, 26 Sep 2014 17:31:57 +0000</pubDate>
      
      <guid>/2014/09/26/analyzing-chinas-post-80s/</guid>
      <description>If you are notÂ fromÂ China or living there, youÂ areÂ probably not familiar withÂ the term å…«é›¶å, orÂ post-80s, but if you are, like me, I think you&amp;rsquo;ll agree that this is probably one of the most widely used and abused terms in modern China. Quite literally, it refers to Chinese people who were born in the 1980s (me included) and the reason it gained so much attention and exposure as compared to, say, ä¹é›¶å (post-90s) or é›¶é›¶å (post-00s), I think, stems from the fact that our generation has simplyÂ seen and been throughÂ way too manyÂ things that have never been seen orÂ experienced by prior generations and are simply taken as norms for later ones.</description>
    </item>
    
    <item>
      <title>What mining my own emails told me about myself</title>
      <link>/2014/09/02/what-mining-my-own-emails-told-me-about-myself/</link>
      <pubDate>Tue, 02 Sep 2014 02:05:07 +0000</pubDate>
      
      <guid>/2014/09/02/what-mining-my-own-emails-told-me-about-myself/</guid>
      <description>On Tuesday last week, I attended a data visualization meetup organized by Data Science LAÂ and the topic was about the most recentÂ Eyeo Festival. Of all the talks that Amelia shared with us, whatÂ impressed me and inspired me the most was Nicholas Felton&amp;rsquo;s personal data projects. In case you are not familiar with him, every year heÂ publishes an annual report that documents his personal data projects / experiments conducted throughout the year.</description>
    </item>
    
    <item>
      <title>Random acts of pizza - a Kaggle competition</title>
      <link>/2014/08/19/random-acts-of-pizza/</link>
      <pubDate>Tue, 19 Aug 2014 06:22:28 +0000</pubDate>
      
      <guid>/2014/08/19/random-acts-of-pizza/</guid>
      <description>This weekend, I participated in a Kaggle not-for-prize competition that uses data obtained from Reddit&amp;rsquo;s Random Acts of Pizza forumÂ to analyze and predict the outcome of a request for pizza, and it was heaps of fun (I always wanted to say that)! Compared with other Kaggle competitions I had tried before, I found this oneÂ a bit easier becauseÂ the dataset is not very large (~5,000 records) and is hence perfect for model experimenting, and, more importantly, the competition is based on a realÂ research done by a couple Stanford researchers, which provides me with a lot of guidelines in how to proceed.</description>
    </item>
    
    <item>
      <title>Filtering twitter timeline</title>
      <link>/2014/08/12/filtered-twitter-timeline/</link>
      <pubDate>Tue, 12 Aug 2014 06:49:26 +0000</pubDate>
      
      <guid>/2014/08/12/filtered-twitter-timeline/</guid>
      <description>Ever felt your twitter newsfeed has too much going on that you don&amp;rsquo;t have time to read them all, let alone digest? I certainly do, even though I only follow like 20 people. Whenever I open the app, I was &amp;ldquo;bombarded&amp;rdquo; by all the new tweetsÂ and, even after scrolling through all of them (asÂ I feel obligated to), I don&amp;rsquo;t feel I have actually taken any new information in. How nice would it be if someone handpicked and highlighted all the useful information for us?</description>
    </item>
    
    <item>
      <title>Location search using Factual and interactive maps using Leaflet</title>
      <link>/2014/08/01/location-search-using-factual-and-interactive-maps-using-leaflet/</link>
      <pubDate>Fri, 01 Aug 2014 06:27:32 +0000</pubDate>
      
      <guid>/2014/08/01/location-search-using-factual-and-interactive-maps-using-leaflet/</guid>
      <description>Leaflet is a popular javascript library forÂ making interactive maps. Don&amp;rsquo;t know how to code in js? No problem, thanks toÂ Ramnath Vaidyanathan, you can now useÂ rChartsÂ to do it in R! Now that we have R Shiny, it just seems a natural thing to combine the two together toÂ make Shiny apps forÂ interactive maps. IfÂ that doesn&amp;rsquo;t motivate you, take a look at these cool examples andÂ roll up your sleeves and make one yourself (example1, example2)!</description>
    </item>
    
    <item>
      <title>State sentiment analysis using twitter live stream and R</title>
      <link>/2014/07/07/state-sentiment-analysis-using-twitter-live-stream-and-r/</link>
      <pubDate>Mon, 07 Jul 2014 03:33:22 +0000</pubDate>
      
      <guid>/2014/07/07/state-sentiment-analysis-using-twitter-live-stream-and-r/</guid>
      <description>This week I started taking this Coursera class called Introduction to Data Science taught by Bill Howe from University of Washington. Although there has only been one lesson so far, my experience has been quite positive particularly due to the interesting programing assignment, which is to use twitter&amp;rsquo;s live stream data to analyze tweet sentiment. If you are interested and want to try yourself, you can readÂ theÂ very helpful instruction hereÂ and clone the git hereÂ (I believe you can access it without signing up for the class, but the courseÂ is free anyway).</description>
    </item>
    
    <item>
      <title>No more finding out about a concert too late</title>
      <link>/2014/07/01/no-more-finding-out-about-a-concert-too-late/</link>
      <pubDate>Tue, 01 Jul 2014 06:40:44 +0000</pubDate>
      
      <guid>/2014/07/01/no-more-finding-out-about-a-concert-too-late/</guid>
      <description>After the numerous times of finding out about a concert too late and ending up either paying a premium or not being able to go, I finally decided to do something about it, and this is what I came up with.
https://runzemc.shinyapps.io/pitchfork/
This R Shiny app I made pulls data from pitchfork automatically every time it&amp;rsquo;s open and shows the upcoming shows per city and per artist (indie artist, to be precise).</description>
    </item>
    
    <item>
      <title>An analysis of the most played artists on KCRW</title>
      <link>/2014/06/22/an-analysis-of-the-most-played-artists-on-kcrw/</link>
      <pubDate>Sun, 22 Jun 2014 04:32:24 +0000</pubDate>
      
      <guid>/2014/06/22/an-analysis-of-the-most-played-artists-on-kcrw/</guid>
      <description>R ShinyÂ is an R package that is designed to easily create and deploy prettyÂ web apps all in the nifty RStudio. Right now, it may not be able to make sophisticated orÂ aesthetically pleasing web apps like d3.js, but,Â byÂ leveraging R&amp;rsquo;s powerhouseÂ analytical capability, I believe it has great potentials.Â One possibleÂ application I can think of is education. Take this k-means app for instance, I wish I had a chance to play with this interactive app when learning about the algorithm myself.</description>
    </item>
    
    <item>
      <title>An analysis of Artsyâ€™s twitter followers</title>
      <link>/2014/05/07/an-analysis-of-artsy-s-twitter-followers/</link>
      <pubDate>Wed, 07 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/05/07/an-analysis-of-artsy-s-twitter-followers/</guid>
      <description>This weekend I decided to learn more about twitter and its handy API. My subject of the analysis is Artsy, a fine-art website that provides a pandora-like service. The subjects I was curious to find out are where their followers are from, what their twitter activities are like, what other interests they have, and, specifically, what kind of stereotypes clusters they fall into because, you know, itâ€™s important and I didnâ€™t have anything better to do.</description>
    </item>
    
  </channel>
</rss>